{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the sample\n",
    "def gen_data():\n",
    "    nobs = 1000\n",
    "    beta = 3\n",
    "    x = np.random.uniform(low=-1., high=1., size=nobs)\n",
    "    e = np.random.uniform(low=-1., high=1., size=nobs) # np.random.normal(loc=0.0, scale=1.0, size=nobs)\n",
    "    y = 1*(1 + beta * x + e >= 0) \n",
    "    return y,x,nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(2, 2)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def ndVuong(model1,model2,alpha,nsims):\n",
    "    \n",
    "    model1_fit = model1.fit(disp=False)\n",
    "    ll1 = model1.loglikeobs(model1_fit.params)\n",
    "    grad1 =  model1.score_obs(model1_fit.params)\n",
    "    hess1 =  model1.hessian(model1_fit.params)\n",
    "    \n",
    "    model2_fit = model2.fit(disp=False)\n",
    "    ll2 = model2.loglikeobs(model2_fit.params)\n",
    "    grad2 =  model2.score_obs(model2_fit.params)\n",
    "    hess2 =  model2.hessian(model2_fit.params)\n",
    "    print(grad2.shape)\n",
    "    print(hess2.shape)\n",
    "    \n",
    "    k1 = len(model1_fit.params)\n",
    "    k2 = len(model2_fit.params)\n",
    "    k = k1 + k2\n",
    "    n = len(ll1)\n",
    "    \n",
    "    #A_hat:\n",
    "    A_hat1 = np.concatenate([hess1,np.zeros((k1,k2))])\n",
    "    A_hat2 = np.concatenate([np.zeros((k2,k1)),-1*hess2])\n",
    "    A_hat = np.concatenate([A_hat1,A_hat2],axis=1)\n",
    "\n",
    "    #B_hat, covariance of the score...\n",
    "    B_hat =  np.concatenate([grad1,-grad2],axis=1) #might be a mistake here..\n",
    "    B_hat = np.cov(B_hat.transpose())\n",
    "    \n",
    "    #compute eigenvalues for weighted chisq\n",
    "    sqrt_B_hat= linalg.sqrtm(B_hat)\n",
    "    W_hat = np.matmul(sqrt_B_hat,linalg.inv(A_hat))\n",
    "    W_hat = np.matmul(W_hat,sqrt_B_hat)\n",
    "    V,W = np.linalg.eig(W_hat)\n",
    "\n",
    "    abs_vecV = np.abs(V)-np.max(np.abs(V));\n",
    "    rho_star = 1*(abs_vecV==0);\n",
    "    rnorm = np.dot(rho_star.transpose(),rho_star)\n",
    "    rho_star = np.dot( 1/np.sqrt(rnorm), rho_star)\n",
    "    rho_star = np.array([rho_star])\n",
    "\n",
    "    #simulate the normal distr asociated with parameters...\n",
    "    np.random.seed()\n",
    "    Z0 = np.random.normal( size=(nsims,k+1) )\n",
    "    VZ1 = np.concatenate( [np.array([[1]]),rho_star.transpose() ])\n",
    "    VZ2 = np.concatenate( [ rho_star,np.identity(k)])\n",
    "    VZ = np.concatenate([VZ1,VZ2],axis=1)\n",
    "\n",
    "    Z = np.matmul(Z0,linalg.sqrtm(VZ))\n",
    "    Z_L = Z[:,0]            #$Z_Lambda$\n",
    "    Z_p = Z[:,1:k+1]        #$Z_phi^\\ast$\n",
    "    \n",
    "    #trace(V)  #diagonostic line\n",
    "    tr_Vsq = (V*V).sum()\n",
    "    V_nmlzd = V/np.sqrt(tr_Vsq) #V, normalized by sqrt(trVsq);\n",
    "\n",
    "    J_Lmod = lambda sig,c: sig*Z_L - np.matmul(Z_p*Z_p,V_nmlzd)/2+ V_nmlzd.sum()/2\n",
    "    \n",
    "    J_omod = (lambda sig,c: sig**2 - 2*sig*np.matmul(Z_p,V_nmlzd*rho_star[0])\n",
    "              + np.matmul(Z_p*Z_p,V_nmlzd*V_nmlzd) + c)\n",
    "    \n",
    "    quant = lambda sig,c: np.quantile( np.abs( J_Lmod(sig,c)/np.sqrt(J_omod(sig,c))) ,1-alpha )\n",
    "\n",
    "    sigstar = lambda c : minimize(lambda sig: -1*quant(sig[0],c), [2.5]).x\n",
    "    cv0 = quant(sigstar(0),0) # critical value with c=0\n",
    "    \n",
    "    z_normal = norm.ppf(1-alpha/2)\n",
    "    z_norm_sim = max(z_normal,np.quantile(np.abs(Z_L),1-alpha)) #simulated z_normal\n",
    "    \n",
    "    \n",
    "    cv = max(cv0,z_normal)\n",
    "    cstar = np.array([0])\n",
    "    \n",
    "    #if cv0 - z_norm_sim > 0.1:  # if critical value with c=0 is not very big\n",
    "    #    f = lambda c: ((quant(sigstar(c[0]),c[0])-z_norm_sim)-0.1)**2\n",
    "    #    cstar =  minimize(f, [5]).x\n",
    "    #    cv = max(quant(sigstar(cstar),cstar),z_normal)\n",
    "    \n",
    "    #Computing the ND test statistic:\n",
    "    nLR_hat = llr = ll1.sum() - ll2.sum()\n",
    "    nomega2_hat = (ll1- ll2).var() ### this line may not be correct #####\n",
    "                                        \n",
    "    #Non-degenerate Vuong Tests    \n",
    "    Tnd = (nLR_hat+V.sum()/2)/np.sqrt(n*nomega2_hat + cstar*(V*V).sum())\n",
    "    \n",
    "    return 1*(Tnd[0] >= cv) + 2*(Tnd[0] <= -cv)\n",
    "    \n",
    "    \n",
    "yn,xn,nobs = gen_data()\n",
    "model1 = sm.Probit(yn,sm.add_constant(xn))\n",
    "model2 = sm.Logit(yn,sm.add_constant(xn))\n",
    "\n",
    "print(ndVuong(model1,model2,.05,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def monte_carlo():\n",
    "    shi = np.array([0, 0 ,0])\n",
    "    total = 1000\n",
    "    \n",
    "    for i in range(total):\n",
    "        np.random.seed()\n",
    "        yn,xn,nobs = gen_data()\n",
    "        model1 = sm.Probit(yn,sm.add_constant(xn))\n",
    "        model1_fit = model1.fit(disp=False)\n",
    "    \n",
    "        model2 = sm.Logit(yn,sm.add_constant(xn))\n",
    "        model2_fit = model2.fit(disp=False)\n",
    "\n",
    "        shi_index = ndVuong(model1,model2,.05,1000)\n",
    "        shi[shi_index] = shi[shi_index] + 1\n",
    "    return shi/total\n",
    "\n",
    "shi = monte_carlo()\n",
    "print(shi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dgp1 - [0.836 0.164 0.   ]\n",
    "#dgp2 - [0.844 0.156 0.   ]\n",
    "#dgp3 - [0.009 0.991 0.   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dependent c*\n",
    "#20 - .2\n",
    "#20 - .3 \n",
    "\n",
    "#c^*=0\n",
    "#1000 - 0.164"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
